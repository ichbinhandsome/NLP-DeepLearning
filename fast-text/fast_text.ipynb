{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0729c69a4684e8a65c2caa3ee004518027c93c29c3ae5e222a8933f5bf005cb71",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../dataset/ag_news/train.csv', index_col=None)\n",
    "df_test = pd.read_csv('../dataset/ag_news/test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Class Index  ...                                        Description\n",
       "0            3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1            3  ...  Reuters - Private investment firm Carlyle Grou...\n",
       "2            3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
       "3            3  ...  Reuters - Authorities have halted oil export\\f...\n",
       "4            3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
       "\n",
       "[5 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class Index</th>\n      <th>Title</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>Reuters - Private investment firm Carlyle Grou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>Reuters - Authorities have halted oil export\\f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Data Preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from torchtext.data import Iterator, BucketIterator, TabularDataset\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据并构建数据迭代器\n",
    "def get_data_iter(train_csv, test_csv, fix_length):\n",
    "\n",
    "    #定义text的对象，定长，小写，tokenizer\n",
    "    TEXT = data.Field(sequential=True, lower=True, tokenize=tokenizer, fix_length=fix_length, batch_first=True)\n",
    "    #定义LABEL对象\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "    train_fields = [(\"label\", LABEL), (\"title\", None), (\"text\", TEXT)]\n",
    "    train = TabularDataset(path=train_csv, format=\"csv\", fields=train_fields, skip_header=True)\n",
    "    train_iter = BucketIterator(train, batch_size=32, device=-1, sort_key=lambda x: len(x.text),\n",
    "                                sort_within_batch=False, repeat=False)\n",
    "\n",
    "    test_fields = [(\"label\", LABEL), (\"title\", None), (\"text\", TEXT)]\n",
    "    test = TabularDataset(path=test_csv, format=\"csv\", fields=test_fields, skip_header=True)\n",
    "    test_iter = Iterator(test, batch_size=32, device=-1, sort=False, sort_within_batch=False, repeat=False)\n",
    "\n",
    "    # vectors = Vectors(name=word2vec_dir)\n",
    "    #构建词表\n",
    "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300))\n",
    "\n",
    "    vocab = TEXT.vocab\n",
    "\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter, vocab = get_data_iter('../dataset/ag_news/train.csv', '../dataset/ag_news/test.csv', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ")\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext 模型\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab, vec_dim, label_size, hidden_size):\n",
    "        super(FastText, self).__init__()\n",
    "        #创建embedding\n",
    "        self.embed = nn.Embedding(len(vocab), vec_dim)\n",
    "        # 若使用预训练的词向量，需在此处指定预训练的权重\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "        self.embed.weight.requires_grad = True\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(vec_dim, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, label_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        # print(x.shape)\n",
    "        out = self.fc(torch.mean(x, dim=1))\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_iter, epoch, lr):\n",
    "    print(\"begin training\")\n",
    "    net.train()  # 必备，将模型设置为训练模式\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epoch):  # 多批次循环\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            # 注意target=batch.label - 1，因为数据集中的label是1，2，3，4，但是pytorch的label默认是从0开始，所以这里需要减1\n",
    "            data, target = batch.text, batch.label - 1\n",
    "            \n",
    "            optimizer.zero_grad()  # 清除所有优化的梯度\n",
    "            \n",
    "            output = net(data)  # 传入数据并前向传播获取输出\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_size = 32\n",
    "            # 打印状态信息\n",
    "            logging.info(\n",
    "                \"train epoch=\" + str(i) + \",batch_id=\" + str(batch_idx) + \",loss=\" + str(loss.item() / batch_size))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(net, test_iter):\n",
    "    net.eval()  # 必备，将模型设置为训练模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(test_iter):\n",
    "            # 注意target=batch.label - 1，因为数据集中的label是1，2，3，4，但是pytorch的label默认是从0开始，所以这里需要减1\n",
    "            data, label = batch.text, batch.label - 1\n",
    "            logging.info(\"test batch_id=\" + str(i))\n",
    "            outputs = net(data)\n",
    "            # torch.max()[0]表示最大值的值，troch.max()[1]表示回最大值的每个索引\n",
    "            # print(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 每个output是一行n列的数据，取一行中最大的值\n",
    "            # print(predicted)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    print('Accuracy of the network on test set: %d %%' % (100 * correct / total))\n",
    "            # test_acc += accuracy_score(torch.argmax(outputs.data, dim=1), label)\n",
    "            # logging.info(\"test_acc=\" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ",833:INFO: train epoch=9,batch_id=3515,loss=2.4113987819873728e-05\n",
      "2021-05-27 01:54:04,906:INFO: train epoch=9,batch_id=3516,loss=0.0008529243059456348\n",
      "2021-05-27 01:54:04,979:INFO: train epoch=9,batch_id=3517,loss=0.00017464750271756202\n",
      "2021-05-27 01:54:05,049:INFO: train epoch=9,batch_id=3518,loss=0.00026773958234116435\n",
      "2021-05-27 01:54:05,123:INFO: train epoch=9,batch_id=3519,loss=0.00011159404675709084\n",
      "2021-05-27 01:54:05,197:INFO: train epoch=9,batch_id=3520,loss=0.0001217150638694875\n",
      "2021-05-27 01:54:05,267:INFO: train epoch=9,batch_id=3521,loss=0.00012172410060884431\n",
      "2021-05-27 01:54:05,339:INFO: train epoch=9,batch_id=3522,loss=0.001380242989398539\n",
      "2021-05-27 01:54:05,412:INFO: train epoch=9,batch_id=3523,loss=4.545645788311958e-05\n",
      "2021-05-27 01:54:05,483:INFO: train epoch=9,batch_id=3524,loss=0.003364759497344494\n",
      "2021-05-27 01:54:05,556:INFO: train epoch=9,batch_id=3525,loss=0.00028856907738372684\n",
      "2021-05-27 01:54:05,628:INFO: train epoch=9,batch_id=3526,loss=0.00032920369994826615\n",
      "2021-05-27 01:54:05,700:INFO: train epoch=9,batch_id=3527,loss=8.222419273806736e-05\n",
      "2021-05-27 01:54:05,773:INFO: train epoch=9,batch_id=3528,loss=0.001960551831871271\n",
      "2021-05-27 01:54:05,845:INFO: train epoch=9,batch_id=3529,loss=0.0031915747094899416\n",
      "2021-05-27 01:54:05,916:INFO: train epoch=9,batch_id=3530,loss=0.0005752641591243446\n",
      "2021-05-27 01:54:05,989:INFO: train epoch=9,batch_id=3531,loss=0.00026121819973923266\n",
      "2021-05-27 01:54:06,061:INFO: train epoch=9,batch_id=3532,loss=0.001184880267828703\n",
      "2021-05-27 01:54:06,132:INFO: train epoch=9,batch_id=3533,loss=8.921816333895549e-05\n",
      "2021-05-27 01:54:06,203:INFO: train epoch=9,batch_id=3534,loss=0.00044531546882353723\n",
      "2021-05-27 01:54:06,276:INFO: train epoch=9,batch_id=3535,loss=4.825741780223325e-05\n",
      "2021-05-27 01:54:06,347:INFO: train epoch=9,batch_id=3536,loss=6.540068716276437e-05\n",
      "2021-05-27 01:54:06,421:INFO: train epoch=9,batch_id=3537,loss=0.0001800200843717903\n",
      "2021-05-27 01:54:06,494:INFO: train epoch=9,batch_id=3538,loss=0.0001826535735744983\n",
      "2021-05-27 01:54:06,565:INFO: train epoch=9,batch_id=3539,loss=0.0026323916390538216\n",
      "2021-05-27 01:54:06,637:INFO: train epoch=9,batch_id=3540,loss=0.00015643922961317003\n",
      "2021-05-27 01:54:06,710:INFO: train epoch=9,batch_id=3541,loss=0.001153210992924869\n",
      "2021-05-27 01:54:06,781:INFO: train epoch=9,batch_id=3542,loss=0.0001947594719240442\n",
      "2021-05-27 01:54:06,854:INFO: train epoch=9,batch_id=3543,loss=3.802233186434023e-05\n",
      "2021-05-27 01:54:06,927:INFO: train epoch=9,batch_id=3544,loss=0.0002082604478346184\n",
      "2021-05-27 01:54:06,998:INFO: train epoch=9,batch_id=3545,loss=0.00016487851098645478\n",
      "2021-05-27 01:54:07,072:INFO: train epoch=9,batch_id=3546,loss=0.0027617602609097958\n",
      "2021-05-27 01:54:07,144:INFO: train epoch=9,batch_id=3547,loss=0.0005671706749126315\n",
      "2021-05-27 01:54:07,215:INFO: train epoch=9,batch_id=3548,loss=0.0016971080331131816\n",
      "2021-05-27 01:54:07,301:INFO: train epoch=9,batch_id=3549,loss=0.0003766111331060529\n",
      "2021-05-27 01:54:07,375:INFO: train epoch=9,batch_id=3550,loss=0.00019128795247524977\n",
      "2021-05-27 01:54:07,460:INFO: train epoch=9,batch_id=3551,loss=0.00015321285172831267\n",
      "2021-05-27 01:54:07,585:INFO: train epoch=9,batch_id=3552,loss=8.813617751002312e-05\n",
      "2021-05-27 01:54:07,700:INFO: train epoch=9,batch_id=3553,loss=0.0007888742256909609\n",
      "2021-05-27 01:54:07,782:INFO: train epoch=9,batch_id=3554,loss=0.00027427286840975285\n",
      "2021-05-27 01:54:07,861:INFO: train epoch=9,batch_id=3555,loss=0.0011817559134215117\n",
      "2021-05-27 01:54:07,943:INFO: train epoch=9,batch_id=3556,loss=4.598707164404914e-05\n",
      "2021-05-27 01:54:08,070:INFO: train epoch=9,batch_id=3557,loss=0.0016818990698084235\n",
      "2021-05-27 01:54:08,168:INFO: train epoch=9,batch_id=3558,loss=0.002162148943170905\n",
      "2021-05-27 01:54:08,244:INFO: train epoch=9,batch_id=3559,loss=0.00011942899436689913\n",
      "2021-05-27 01:54:08,315:INFO: train epoch=9,batch_id=3560,loss=9.246054105460644e-05\n",
      "2021-05-27 01:54:08,385:INFO: train epoch=9,batch_id=3561,loss=0.001867847633548081\n",
      "2021-05-27 01:54:08,480:INFO: train epoch=9,batch_id=3562,loss=3.451637167017907e-05\n",
      "2021-05-27 01:54:08,557:INFO: train epoch=9,batch_id=3563,loss=0.000575279991608113\n",
      "2021-05-27 01:54:08,627:INFO: train epoch=9,batch_id=3564,loss=0.0012140643084421754\n",
      "2021-05-27 01:54:08,696:INFO: train epoch=9,batch_id=3565,loss=2.6883964892476797e-05\n",
      "2021-05-27 01:54:08,766:INFO: train epoch=9,batch_id=3566,loss=0.0004066934052389115\n",
      "2021-05-27 01:54:08,835:INFO: train epoch=9,batch_id=3567,loss=2.0646521079470403e-05\n",
      "2021-05-27 01:54:08,905:INFO: train epoch=9,batch_id=3568,loss=0.004659074358642101\n",
      "2021-05-27 01:54:08,975:INFO: train epoch=9,batch_id=3569,loss=6.336713704513386e-05\n",
      "2021-05-27 01:54:09,045:INFO: train epoch=9,batch_id=3570,loss=0.00015789413009770215\n",
      "2021-05-27 01:54:09,115:INFO: train epoch=9,batch_id=3571,loss=0.00034434840199537575\n",
      "2021-05-27 01:54:09,185:INFO: train epoch=9,batch_id=3572,loss=0.00024402138660661876\n",
      "2021-05-27 01:54:09,256:INFO: train epoch=9,batch_id=3573,loss=0.00018662403454072773\n",
      "2021-05-27 01:54:09,328:INFO: train epoch=9,batch_id=3574,loss=0.002539478475227952\n",
      "2021-05-27 01:54:09,397:INFO: train epoch=9,batch_id=3575,loss=9.696168490336277e-06\n",
      "2021-05-27 01:54:09,467:INFO: train epoch=9,batch_id=3576,loss=0.00025609717704355717\n",
      "2021-05-27 01:54:09,537:INFO: train epoch=9,batch_id=3577,loss=0.0020903872791677713\n",
      "2021-05-27 01:54:09,607:INFO: train epoch=9,batch_id=3578,loss=0.00012767742737196386\n",
      "2021-05-27 01:54:09,677:INFO: train epoch=9,batch_id=3579,loss=0.0008145879837684333\n",
      "2021-05-27 01:54:09,747:INFO: train epoch=9,batch_id=3580,loss=0.002924799919128418\n",
      "2021-05-27 01:54:09,816:INFO: train epoch=9,batch_id=3581,loss=0.000687839521560818\n",
      "2021-05-27 01:54:09,886:INFO: train epoch=9,batch_id=3582,loss=0.001787338056601584\n",
      "2021-05-27 01:54:09,955:INFO: train epoch=9,batch_id=3583,loss=0.0007491945289075375\n",
      "2021-05-27 01:54:10,025:INFO: train epoch=9,batch_id=3584,loss=0.001219211844727397\n",
      "2021-05-27 01:54:10,100:INFO: train epoch=9,batch_id=3585,loss=0.0062812212854623795\n",
      "2021-05-27 01:54:10,169:INFO: train epoch=9,batch_id=3586,loss=0.0010422745253890753\n",
      "2021-05-27 01:54:10,239:INFO: train epoch=9,batch_id=3587,loss=0.0016999905928969383\n",
      "2021-05-27 01:54:10,309:INFO: train epoch=9,batch_id=3588,loss=0.00011230347445234656\n",
      "2021-05-27 01:54:10,381:INFO: train epoch=9,batch_id=3589,loss=0.0023293420672416687\n",
      "2021-05-27 01:54:10,451:INFO: train epoch=9,batch_id=3590,loss=0.0008483273559249938\n",
      "2021-05-27 01:54:10,520:INFO: train epoch=9,batch_id=3591,loss=0.0013431969564408064\n",
      "2021-05-27 01:54:10,590:INFO: train epoch=9,batch_id=3592,loss=0.0006958674639463425\n",
      "2021-05-27 01:54:10,659:INFO: train epoch=9,batch_id=3593,loss=0.00020400300854817033\n",
      "2021-05-27 01:54:10,730:INFO: train epoch=9,batch_id=3594,loss=0.00013985582336317748\n",
      "2021-05-27 01:54:10,800:INFO: train epoch=9,batch_id=3595,loss=8.952694770414382e-05\n",
      "2021-05-27 01:54:10,869:INFO: train epoch=9,batch_id=3596,loss=0.0001089505894924514\n",
      "2021-05-27 01:54:10,939:INFO: train epoch=9,batch_id=3597,loss=0.0014084281865507364\n",
      "2021-05-27 01:54:11,009:INFO: train epoch=9,batch_id=3598,loss=0.0004815159772988409\n",
      "2021-05-27 01:54:11,100:INFO: train epoch=9,batch_id=3599,loss=0.0006799223483540118\n",
      "2021-05-27 01:54:11,192:INFO: train epoch=9,batch_id=3600,loss=0.00015377113595604897\n",
      "2021-05-27 01:54:11,280:INFO: train epoch=9,batch_id=3601,loss=0.00037565460661426187\n",
      "2021-05-27 01:54:11,353:INFO: train epoch=9,batch_id=3602,loss=0.00482904864475131\n",
      "2021-05-27 01:54:11,427:INFO: train epoch=9,batch_id=3603,loss=0.0004953629104420543\n",
      "2021-05-27 01:54:11,496:INFO: train epoch=9,batch_id=3604,loss=1.771086135704536e-05\n",
      "2021-05-27 01:54:11,570:INFO: train epoch=9,batch_id=3605,loss=0.0008017127402126789\n",
      "2021-05-27 01:54:11,640:INFO: train epoch=9,batch_id=3606,loss=0.0025947841349989176\n",
      "2021-05-27 01:54:11,709:INFO: train epoch=9,batch_id=3607,loss=5.0315506086917594e-05\n",
      "2021-05-27 01:54:11,779:INFO: train epoch=9,batch_id=3608,loss=0.0003438925778027624\n",
      "2021-05-27 01:54:11,849:INFO: train epoch=9,batch_id=3609,loss=0.00019097563927061856\n",
      "2021-05-27 01:54:11,919:INFO: train epoch=9,batch_id=3610,loss=0.0011304720537737012\n",
      "2021-05-27 01:54:11,989:INFO: train epoch=9,batch_id=3611,loss=0.0020239902660250664\n",
      "2021-05-27 01:54:12,059:INFO: train epoch=9,batch_id=3612,loss=0.0003291452012490481\n",
      "2021-05-27 01:54:12,128:INFO: train epoch=9,batch_id=3613,loss=0.00021662519429810345\n",
      "2021-05-27 01:54:12,198:INFO: train epoch=9,batch_id=3614,loss=0.0016199168749153614\n",
      "2021-05-27 01:54:12,268:INFO: train epoch=9,batch_id=3615,loss=0.001108412747271359\n",
      "2021-05-27 01:54:12,337:INFO: train epoch=9,batch_id=3616,loss=0.0007345259073190391\n",
      "2021-05-27 01:54:12,411:INFO: train epoch=9,batch_id=3617,loss=7.306324550881982e-05\n",
      "2021-05-27 01:54:12,481:INFO: train epoch=9,batch_id=3618,loss=7.9976802226156e-05\n",
      "2021-05-27 01:54:12,553:INFO: train epoch=9,batch_id=3619,loss=0.0006022616871632636\n",
      "2021-05-27 01:54:12,622:INFO: train epoch=9,batch_id=3620,loss=8.078411337919533e-05\n",
      "2021-05-27 01:54:12,694:INFO: train epoch=9,batch_id=3621,loss=0.00010116371413460001\n",
      "2021-05-27 01:54:12,763:INFO: train epoch=9,batch_id=3622,loss=4.0866998460842296e-05\n",
      "2021-05-27 01:54:12,833:INFO: train epoch=9,batch_id=3623,loss=0.0034494881983846426\n",
      "2021-05-27 01:54:12,902:INFO: train epoch=9,batch_id=3624,loss=0.0010394364362582564\n",
      "2021-05-27 01:54:12,972:INFO: train epoch=9,batch_id=3625,loss=0.00025910779368132353\n",
      "2021-05-27 01:54:13,042:INFO: train epoch=9,batch_id=3626,loss=0.00016963428060989827\n",
      "2021-05-27 01:54:13,111:INFO: train epoch=9,batch_id=3627,loss=0.0018290556035935879\n",
      "2021-05-27 01:54:13,181:INFO: train epoch=9,batch_id=3628,loss=0.009940260089933872\n",
      "2021-05-27 01:54:13,251:INFO: train epoch=9,batch_id=3629,loss=0.0010352091630920768\n",
      "2021-05-27 01:54:13,321:INFO: train epoch=9,batch_id=3630,loss=0.0013127392157912254\n",
      "2021-05-27 01:54:13,390:INFO: train epoch=9,batch_id=3631,loss=0.0002833361504599452\n",
      "2021-05-27 01:54:13,462:INFO: train epoch=9,batch_id=3632,loss=0.0018351743929088116\n",
      "2021-05-27 01:54:13,531:INFO: train epoch=9,batch_id=3633,loss=0.0004521622904576361\n",
      "2021-05-27 01:54:13,601:INFO: train epoch=9,batch_id=3634,loss=0.0021110360976308584\n",
      "2021-05-27 01:54:13,671:INFO: train epoch=9,batch_id=3635,loss=4.681165955844335e-05\n",
      "2021-05-27 01:54:13,741:INFO: train epoch=9,batch_id=3636,loss=0.00515738595277071\n",
      "2021-05-27 01:54:13,811:INFO: train epoch=9,batch_id=3637,loss=0.00038599001709371805\n",
      "2021-05-27 01:54:13,880:INFO: train epoch=9,batch_id=3638,loss=0.00021897739497944713\n",
      "2021-05-27 01:54:13,950:INFO: train epoch=9,batch_id=3639,loss=0.0002678193850442767\n",
      "2021-05-27 01:54:14,019:INFO: train epoch=9,batch_id=3640,loss=0.00013188994489610195\n",
      "2021-05-27 01:54:14,096:INFO: train epoch=9,batch_id=3641,loss=0.001988571137189865\n",
      "2021-05-27 01:54:14,172:INFO: train epoch=9,batch_id=3642,loss=0.0007440336630679667\n",
      "2021-05-27 01:54:14,242:INFO: train epoch=9,batch_id=3643,loss=3.394966188352555e-05\n",
      "2021-05-27 01:54:14,311:INFO: train epoch=9,batch_id=3644,loss=0.0006471701781265438\n",
      "2021-05-27 01:54:14,380:INFO: train epoch=9,batch_id=3645,loss=0.001126869348809123\n",
      "2021-05-27 01:54:14,453:INFO: train epoch=9,batch_id=3646,loss=0.0032649305649101734\n",
      "2021-05-27 01:54:14,531:INFO: train epoch=9,batch_id=3647,loss=0.0008755772141739726\n",
      "2021-05-27 01:54:14,601:INFO: train epoch=9,batch_id=3648,loss=0.0009494030964560807\n",
      "2021-05-27 01:54:14,670:INFO: train epoch=9,batch_id=3649,loss=0.0013920653145760298\n",
      "2021-05-27 01:54:14,740:INFO: train epoch=9,batch_id=3650,loss=0.00010220399417448789\n",
      "2021-05-27 01:54:14,810:INFO: train epoch=9,batch_id=3651,loss=0.0016360008157789707\n",
      "2021-05-27 01:54:14,879:INFO: train epoch=9,batch_id=3652,loss=0.0002730396226979792\n",
      "2021-05-27 01:54:14,948:INFO: train epoch=9,batch_id=3653,loss=0.0016083871014416218\n",
      "2021-05-27 01:54:15,018:INFO: train epoch=9,batch_id=3654,loss=0.0014070018660277128\n",
      "2021-05-27 01:54:15,087:INFO: train epoch=9,batch_id=3655,loss=0.00023963296553120017\n",
      "2021-05-27 01:54:15,157:INFO: train epoch=9,batch_id=3656,loss=3.276844654465094e-05\n",
      "2021-05-27 01:54:15,227:INFO: train epoch=9,batch_id=3657,loss=0.001376334228552878\n",
      "2021-05-27 01:54:15,302:INFO: train epoch=9,batch_id=3658,loss=0.0010138489305973053\n",
      "2021-05-27 01:54:15,372:INFO: train epoch=9,batch_id=3659,loss=0.0008067417657002807\n",
      "2021-05-27 01:54:15,442:INFO: train epoch=9,batch_id=3660,loss=0.0009544938802719116\n",
      "2021-05-27 01:54:15,511:INFO: train epoch=9,batch_id=3661,loss=0.00024250539718195796\n",
      "2021-05-27 01:54:15,582:INFO: train epoch=9,batch_id=3662,loss=8.106953464448452e-05\n",
      "2021-05-27 01:54:15,652:INFO: train epoch=9,batch_id=3663,loss=0.0028100458439439535\n",
      "2021-05-27 01:54:15,721:INFO: train epoch=9,batch_id=3664,loss=0.0004561802779790014\n",
      "2021-05-27 01:54:15,791:INFO: train epoch=9,batch_id=3665,loss=0.0003991711128037423\n",
      "2021-05-27 01:54:15,860:INFO: train epoch=9,batch_id=3666,loss=1.9328859707457013e-05\n",
      "2021-05-27 01:54:15,930:INFO: train epoch=9,batch_id=3667,loss=0.001560838078148663\n",
      "2021-05-27 01:54:16,001:INFO: train epoch=9,batch_id=3668,loss=0.00018497549172025174\n",
      "2021-05-27 01:54:16,071:INFO: train epoch=9,batch_id=3669,loss=0.00021220352209638804\n",
      "2021-05-27 01:54:16,140:INFO: train epoch=9,batch_id=3670,loss=0.0005538564291782677\n",
      "2021-05-27 01:54:16,210:INFO: train epoch=9,batch_id=3671,loss=0.0005148108466528356\n",
      "2021-05-27 01:54:16,280:INFO: train epoch=9,batch_id=3672,loss=0.0024800202809274197\n",
      "2021-05-27 01:54:16,349:INFO: train epoch=9,batch_id=3673,loss=0.006230930797755718\n",
      "2021-05-27 01:54:16,419:INFO: train epoch=9,batch_id=3674,loss=1.1829601135104895e-05\n",
      "2021-05-27 01:54:16,488:INFO: train epoch=9,batch_id=3675,loss=4.0450475353281945e-05\n",
      "2021-05-27 01:54:16,560:INFO: train epoch=9,batch_id=3676,loss=4.908816481474787e-05\n",
      "2021-05-27 01:54:16,630:INFO: train epoch=9,batch_id=3677,loss=0.0020165948662906885\n",
      "2021-05-27 01:54:16,700:INFO: train epoch=9,batch_id=3678,loss=5.7274977734778076e-05\n",
      "2021-05-27 01:54:16,769:INFO: train epoch=9,batch_id=3679,loss=2.1123412807355635e-05\n",
      "2021-05-27 01:54:16,839:INFO: train epoch=9,batch_id=3680,loss=0.0014518207171931863\n",
      "2021-05-27 01:54:16,908:INFO: train epoch=9,batch_id=3681,loss=0.003757658414542675\n",
      "2021-05-27 01:54:16,979:INFO: train epoch=9,batch_id=3682,loss=0.0004055863246321678\n",
      "2021-05-27 01:54:17,048:INFO: train epoch=9,batch_id=3683,loss=0.001062162104062736\n",
      "2021-05-27 01:54:17,118:INFO: train epoch=9,batch_id=3684,loss=0.005637425929307938\n",
      "2021-05-27 01:54:17,188:INFO: train epoch=9,batch_id=3685,loss=0.0018336655339226127\n",
      "2021-05-27 01:54:17,258:INFO: train epoch=9,batch_id=3686,loss=0.0020903609693050385\n",
      "2021-05-27 01:54:17,329:INFO: train epoch=9,batch_id=3687,loss=0.0017293270211666822\n",
      "2021-05-27 01:54:17,398:INFO: train epoch=9,batch_id=3688,loss=0.00024392266641370952\n",
      "2021-05-27 01:54:17,468:INFO: train epoch=9,batch_id=3689,loss=0.0011913056951016188\n",
      "2021-05-27 01:54:17,537:INFO: train epoch=9,batch_id=3690,loss=0.0013693218352273107\n",
      "2021-05-27 01:54:17,610:INFO: train epoch=9,batch_id=3691,loss=0.00017300558101851493\n",
      "2021-05-27 01:54:17,679:INFO: train epoch=9,batch_id=3692,loss=1.6177131328731775e-05\n",
      "2021-05-27 01:54:17,749:INFO: train epoch=9,batch_id=3693,loss=0.0022178003564476967\n",
      "2021-05-27 01:54:17,819:INFO: train epoch=9,batch_id=3694,loss=0.0004631000629160553\n",
      "2021-05-27 01:54:17,888:INFO: train epoch=9,batch_id=3695,loss=0.0002647306537255645\n",
      "2021-05-27 01:54:17,958:INFO: train epoch=9,batch_id=3696,loss=0.0008273645653389394\n",
      "2021-05-27 01:54:18,027:INFO: train epoch=9,batch_id=3697,loss=0.00023955000506248325\n",
      "2021-05-27 01:54:18,097:INFO: train epoch=9,batch_id=3698,loss=0.00011563327279873192\n",
      "2021-05-27 01:54:18,168:INFO: train epoch=9,batch_id=3699,loss=0.0001241344871232286\n",
      "2021-05-27 01:54:18,238:INFO: train epoch=9,batch_id=3700,loss=6.84414480929263e-05\n",
      "2021-05-27 01:54:18,307:INFO: train epoch=9,batch_id=3701,loss=0.0036976784467697144\n",
      "2021-05-27 01:54:18,377:INFO: train epoch=9,batch_id=3702,loss=0.0002305137604707852\n",
      "2021-05-27 01:54:18,447:INFO: train epoch=9,batch_id=3703,loss=0.0004016859456896782\n",
      "2021-05-27 01:54:18,516:INFO: train epoch=9,batch_id=3704,loss=0.0066544548608362675\n",
      "2021-05-27 01:54:18,586:INFO: train epoch=9,batch_id=3705,loss=0.0017814741004258394\n",
      "2021-05-27 01:54:18,659:INFO: train epoch=9,batch_id=3706,loss=0.0018307962454855442\n",
      "2021-05-27 01:54:18,728:INFO: train epoch=9,batch_id=3707,loss=8.011703175725415e-05\n",
      "2021-05-27 01:54:18,798:INFO: train epoch=9,batch_id=3708,loss=0.0036112808156758547\n",
      "2021-05-27 01:54:18,867:INFO: train epoch=9,batch_id=3709,loss=0.002023120876401663\n",
      "2021-05-27 01:54:18,937:INFO: train epoch=9,batch_id=3710,loss=0.0007709087221883237\n",
      "2021-05-27 01:54:19,007:INFO: train epoch=9,batch_id=3711,loss=0.0015586918452754617\n",
      "2021-05-27 01:54:19,076:INFO: train epoch=9,batch_id=3712,loss=0.001968121388927102\n",
      "2021-05-27 01:54:19,146:INFO: train epoch=9,batch_id=3713,loss=0.000676371157169342\n",
      "2021-05-27 01:54:19,222:INFO: train epoch=9,batch_id=3714,loss=0.00010913532605627552\n",
      "2021-05-27 01:54:19,291:INFO: train epoch=9,batch_id=3715,loss=0.0002141416334779933\n",
      "2021-05-27 01:54:19,361:INFO: train epoch=9,batch_id=3716,loss=0.00040634218021295965\n",
      "2021-05-27 01:54:19,430:INFO: train epoch=9,batch_id=3717,loss=0.0009356759837828577\n",
      "2021-05-27 01:54:19,500:INFO: train epoch=9,batch_id=3718,loss=0.0002615320263430476\n",
      "2021-05-27 01:54:19,575:INFO: train epoch=9,batch_id=3719,loss=0.0025620220694690943\n",
      "2021-05-27 01:54:19,654:INFO: train epoch=9,batch_id=3720,loss=0.0017407442210242152\n",
      "2021-05-27 01:54:19,723:INFO: train epoch=9,batch_id=3721,loss=0.00039471773197874427\n",
      "2021-05-27 01:54:19,794:INFO: train epoch=9,batch_id=3722,loss=0.00012483536556828767\n",
      "2021-05-27 01:54:19,864:INFO: train epoch=9,batch_id=3723,loss=0.00041761339525692165\n",
      "2021-05-27 01:54:19,933:INFO: train epoch=9,batch_id=3724,loss=0.0014244215562939644\n",
      "2021-05-27 01:54:20,003:INFO: train epoch=9,batch_id=3725,loss=0.003852277295663953\n",
      "2021-05-27 01:54:20,073:INFO: train epoch=9,batch_id=3726,loss=8.352143049705774e-05\n",
      "2021-05-27 01:54:20,143:INFO: train epoch=9,batch_id=3727,loss=7.57778252591379e-05\n",
      "2021-05-27 01:54:20,212:INFO: train epoch=9,batch_id=3728,loss=0.0016060859197750688\n",
      "2021-05-27 01:54:20,282:INFO: train epoch=9,batch_id=3729,loss=0.00012936834536958486\n",
      "2021-05-27 01:54:20,352:INFO: train epoch=9,batch_id=3730,loss=0.00017825199756771326\n",
      "2021-05-27 01:54:20,421:INFO: train epoch=9,batch_id=3731,loss=0.00041061564115807414\n",
      "2021-05-27 01:54:20,491:INFO: train epoch=9,batch_id=3732,loss=2.6241003070026636e-05\n",
      "2021-05-27 01:54:20,561:INFO: train epoch=9,batch_id=3733,loss=0.001244344632141292\n",
      "2021-05-27 01:54:20,631:INFO: train epoch=9,batch_id=3734,loss=0.0007979327347129583\n",
      "2021-05-27 01:54:20,702:INFO: train epoch=9,batch_id=3735,loss=0.007103544659912586\n",
      "2021-05-27 01:54:20,772:INFO: train epoch=9,batch_id=3736,loss=0.0008753514848649502\n",
      "2021-05-27 01:54:20,842:INFO: train epoch=9,batch_id=3737,loss=0.0009949803352355957\n",
      "2021-05-27 01:54:20,911:INFO: train epoch=9,batch_id=3738,loss=7.359362643910572e-05\n",
      "2021-05-27 01:54:20,981:INFO: train epoch=9,batch_id=3739,loss=0.002843523630872369\n",
      "2021-05-27 01:54:21,050:INFO: train epoch=9,batch_id=3740,loss=0.00017390867287758738\n",
      "2021-05-27 01:54:21,120:INFO: train epoch=9,batch_id=3741,loss=0.00020357653556857258\n",
      "2021-05-27 01:54:21,190:INFO: train epoch=9,batch_id=3742,loss=0.0007439266773872077\n",
      "2021-05-27 01:54:21,259:INFO: train epoch=9,batch_id=3743,loss=5.353638334781863e-05\n",
      "2021-05-27 01:54:21,329:INFO: train epoch=9,batch_id=3744,loss=0.0013358339201658964\n",
      "2021-05-27 01:54:21,400:INFO: train epoch=9,batch_id=3745,loss=0.0011128102196380496\n",
      "2021-05-27 01:54:21,469:INFO: train epoch=9,batch_id=3746,loss=3.9986840420169756e-05\n",
      "2021-05-27 01:54:21,538:INFO: train epoch=9,batch_id=3747,loss=6.29264977760613e-05\n",
      "2021-05-27 01:54:21,608:INFO: train epoch=9,batch_id=3748,loss=0.00043250987073406577\n",
      "2021-05-27 01:54:21,677:INFO: train epoch=9,batch_id=3749,loss=0.0023534633219242096\n",
      "Finished Training\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/ag_fasttext_model.pkl'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-c96e5e9e636e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"开始训练模型\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/ag_fasttext_model.pkl'"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s: %(message)s', level=logging.INFO)\n",
    "\n",
    "#save model\n",
    "# net_dir = \"ag_fasttext_model.pkl\"\n",
    "emb_dim = 300\n",
    "hidden_size = 200\n",
    "label_size = 4\n",
    "\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "#batchsize=32\n",
    "\n",
    "net = FastText(vocab=vocab, vec_dim=emb_dim, label_size=label_size, hidden_size=hidden_size)\n",
    "\n",
    "logging.info(\"开始训练模型\")\n",
    "train_model(net, train_iter, epoch, lr)\n",
    "# torch.save(net, net_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dir = \"ag_fasttext_model.pkl\"\n",
    "torch.save(net, net_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-27 02:23:54,839:INFO: test batch_id=0\n",
      "2021-05-27 02:23:54,843:INFO: test batch_id=1\n",
      "2021-05-27 02:23:54,847:INFO: test batch_id=2\n",
      "2021-05-27 02:23:54,851:INFO: test batch_id=3\n",
      "2021-05-27 02:23:54,854:INFO: test batch_id=4\n",
      "2021-05-27 02:23:54,857:INFO: test batch_id=5\n",
      "2021-05-27 02:23:54,860:INFO: test batch_id=6\n",
      "2021-05-27 02:23:54,863:INFO: test batch_id=7\n",
      "2021-05-27 02:23:54,866:INFO: test batch_id=8\n",
      "2021-05-27 02:23:54,869:INFO: test batch_id=9\n",
      "2021-05-27 02:23:54,871:INFO: test batch_id=10\n",
      "2021-05-27 02:23:54,874:INFO: test batch_id=11\n",
      "2021-05-27 02:23:54,878:INFO: test batch_id=12\n",
      "2021-05-27 02:23:54,881:INFO: test batch_id=13\n",
      "2021-05-27 02:23:54,884:INFO: test batch_id=14\n",
      "2021-05-27 02:23:54,887:INFO: test batch_id=15\n",
      "2021-05-27 02:23:54,889:INFO: test batch_id=16\n",
      "2021-05-27 02:23:54,892:INFO: test batch_id=17\n",
      "2021-05-27 02:23:54,895:INFO: test batch_id=18\n",
      "2021-05-27 02:23:54,899:INFO: test batch_id=19\n",
      "2021-05-27 02:23:54,902:INFO: test batch_id=20\n",
      "2021-05-27 02:23:54,905:INFO: test batch_id=21\n",
      "2021-05-27 02:23:54,908:INFO: test batch_id=22\n",
      "2021-05-27 02:23:54,911:INFO: test batch_id=23\n",
      "2021-05-27 02:23:54,915:INFO: test batch_id=24\n",
      "2021-05-27 02:23:54,918:INFO: test batch_id=25\n",
      "2021-05-27 02:23:54,920:INFO: test batch_id=26\n",
      "2021-05-27 02:23:54,923:INFO: test batch_id=27\n",
      "2021-05-27 02:23:54,927:INFO: test batch_id=28\n",
      "2021-05-27 02:23:54,929:INFO: test batch_id=29\n",
      "2021-05-27 02:23:54,932:INFO: test batch_id=30\n",
      "2021-05-27 02:23:54,936:INFO: test batch_id=31\n",
      "2021-05-27 02:23:54,940:INFO: test batch_id=32\n",
      "2021-05-27 02:23:54,943:INFO: test batch_id=33\n",
      "2021-05-27 02:23:54,946:INFO: test batch_id=34\n",
      "2021-05-27 02:23:54,951:INFO: test batch_id=35\n",
      "2021-05-27 02:23:54,954:INFO: test batch_id=36\n",
      "2021-05-27 02:23:54,957:INFO: test batch_id=37\n",
      "2021-05-27 02:23:54,960:INFO: test batch_id=38\n",
      "2021-05-27 02:23:54,963:INFO: test batch_id=39\n",
      "2021-05-27 02:23:54,966:INFO: test batch_id=40\n",
      "2021-05-27 02:23:54,969:INFO: test batch_id=41\n",
      "2021-05-27 02:23:54,973:INFO: test batch_id=42\n",
      "2021-05-27 02:23:54,977:INFO: test batch_id=43\n",
      "2021-05-27 02:23:54,980:INFO: test batch_id=44\n",
      "2021-05-27 02:23:54,983:INFO: test batch_id=45\n",
      "2021-05-27 02:23:54,987:INFO: test batch_id=46\n",
      "2021-05-27 02:23:54,990:INFO: test batch_id=47\n",
      "2021-05-27 02:23:54,993:INFO: test batch_id=48\n",
      "2021-05-27 02:23:54,997:INFO: test batch_id=49\n",
      "2021-05-27 02:23:55,000:INFO: test batch_id=50\n",
      "2021-05-27 02:23:55,003:INFO: test batch_id=51\n",
      "2021-05-27 02:23:55,006:INFO: test batch_id=52\n",
      "2021-05-27 02:23:55,009:INFO: test batch_id=53\n",
      "2021-05-27 02:23:55,013:INFO: test batch_id=54\n",
      "2021-05-27 02:23:55,016:INFO: test batch_id=55\n",
      "2021-05-27 02:23:55,019:INFO: test batch_id=56\n",
      "2021-05-27 02:23:55,022:INFO: test batch_id=57\n",
      "2021-05-27 02:23:55,026:INFO: test batch_id=58\n",
      "2021-05-27 02:23:55,030:INFO: test batch_id=59\n",
      "2021-05-27 02:23:55,033:INFO: test batch_id=60\n",
      "2021-05-27 02:23:55,035:INFO: test batch_id=61\n",
      "2021-05-27 02:23:55,039:INFO: test batch_id=62\n",
      "2021-05-27 02:23:55,041:INFO: test batch_id=63\n",
      "2021-05-27 02:23:55,045:INFO: test batch_id=64\n",
      "2021-05-27 02:23:55,048:INFO: test batch_id=65\n",
      "2021-05-27 02:23:55,051:INFO: test batch_id=66\n",
      "2021-05-27 02:23:55,054:INFO: test batch_id=67\n",
      "2021-05-27 02:23:55,057:INFO: test batch_id=68\n",
      "2021-05-27 02:23:55,060:INFO: test batch_id=69\n",
      "2021-05-27 02:23:55,063:INFO: test batch_id=70\n",
      "2021-05-27 02:23:55,066:INFO: test batch_id=71\n",
      "2021-05-27 02:23:55,069:INFO: test batch_id=72\n",
      "2021-05-27 02:23:55,072:INFO: test batch_id=73\n",
      "2021-05-27 02:23:55,075:INFO: test batch_id=74\n",
      "2021-05-27 02:23:55,079:INFO: test batch_id=75\n",
      "2021-05-27 02:23:55,082:INFO: test batch_id=76\n",
      "2021-05-27 02:23:55,085:INFO: test batch_id=77\n",
      "2021-05-27 02:23:55,088:INFO: test batch_id=78\n",
      "2021-05-27 02:23:55,091:INFO: test batch_id=79\n",
      "2021-05-27 02:23:55,094:INFO: test batch_id=80\n",
      "2021-05-27 02:23:55,097:INFO: test batch_id=81\n",
      "2021-05-27 02:23:55,100:INFO: test batch_id=82\n",
      "2021-05-27 02:23:55,103:INFO: test batch_id=83\n",
      "2021-05-27 02:23:55,106:INFO: test batch_id=84\n",
      "2021-05-27 02:23:55,110:INFO: test batch_id=85\n",
      "2021-05-27 02:23:55,113:INFO: test batch_id=86\n",
      "2021-05-27 02:23:55,116:INFO: test batch_id=87\n",
      "2021-05-27 02:23:55,119:INFO: test batch_id=88\n",
      "2021-05-27 02:23:55,122:INFO: test batch_id=89\n",
      "2021-05-27 02:23:55,125:INFO: test batch_id=90\n",
      "2021-05-27 02:23:55,129:INFO: test batch_id=91\n",
      "2021-05-27 02:23:55,134:INFO: test batch_id=92\n",
      "2021-05-27 02:23:55,138:INFO: test batch_id=93\n",
      "2021-05-27 02:23:55,143:INFO: test batch_id=94\n",
      "2021-05-27 02:23:55,147:INFO: test batch_id=95\n",
      "2021-05-27 02:23:55,150:INFO: test batch_id=96\n",
      "2021-05-27 02:23:55,154:INFO: test batch_id=97\n",
      "2021-05-27 02:23:55,158:INFO: test batch_id=98\n",
      "2021-05-27 02:23:55,161:INFO: test batch_id=99\n",
      "2021-05-27 02:23:55,170:INFO: test batch_id=100\n",
      "2021-05-27 02:23:55,183:INFO: test batch_id=101\n",
      "2021-05-27 02:23:55,185:INFO: test batch_id=102\n",
      "2021-05-27 02:23:55,189:INFO: test batch_id=103\n",
      "2021-05-27 02:23:55,193:INFO: test batch_id=104\n",
      "2021-05-27 02:23:55,196:INFO: test batch_id=105\n",
      "2021-05-27 02:23:55,199:INFO: test batch_id=106\n",
      "2021-05-27 02:23:55,206:INFO: test batch_id=107\n",
      "2021-05-27 02:23:55,209:INFO: test batch_id=108\n",
      "2021-05-27 02:23:55,212:INFO: test batch_id=109\n",
      "2021-05-27 02:23:55,215:INFO: test batch_id=110\n",
      "2021-05-27 02:23:55,218:INFO: test batch_id=111\n",
      "2021-05-27 02:23:55,221:INFO: test batch_id=112\n",
      "2021-05-27 02:23:55,224:INFO: test batch_id=113\n",
      "2021-05-27 02:23:55,227:INFO: test batch_id=114\n",
      "2021-05-27 02:23:55,229:INFO: test batch_id=115\n",
      "2021-05-27 02:23:55,232:INFO: test batch_id=116\n",
      "2021-05-27 02:23:55,235:INFO: test batch_id=117\n",
      "2021-05-27 02:23:55,237:INFO: test batch_id=118\n",
      "2021-05-27 02:23:55,240:INFO: test batch_id=119\n",
      "2021-05-27 02:23:55,243:INFO: test batch_id=120\n",
      "2021-05-27 02:23:55,246:INFO: test batch_id=121\n",
      "2021-05-27 02:23:55,249:INFO: test batch_id=122\n",
      "2021-05-27 02:23:55,252:INFO: test batch_id=123\n",
      "2021-05-27 02:23:55,254:INFO: test batch_id=124\n",
      "2021-05-27 02:23:55,257:INFO: test batch_id=125\n",
      "2021-05-27 02:23:55,260:INFO: test batch_id=126\n",
      "2021-05-27 02:23:55,263:INFO: test batch_id=127\n",
      "2021-05-27 02:23:55,268:INFO: test batch_id=128\n",
      "2021-05-27 02:23:55,271:INFO: test batch_id=129\n",
      "2021-05-27 02:23:55,274:INFO: test batch_id=130\n",
      "2021-05-27 02:23:55,277:INFO: test batch_id=131\n",
      "2021-05-27 02:23:55,280:INFO: test batch_id=132\n",
      "2021-05-27 02:23:55,284:INFO: test batch_id=133\n",
      "2021-05-27 02:23:55,287:INFO: test batch_id=134\n",
      "2021-05-27 02:23:55,290:INFO: test batch_id=135\n",
      "2021-05-27 02:23:55,293:INFO: test batch_id=136\n",
      "2021-05-27 02:23:55,296:INFO: test batch_id=137\n",
      "2021-05-27 02:23:55,299:INFO: test batch_id=138\n",
      "2021-05-27 02:23:55,302:INFO: test batch_id=139\n",
      "2021-05-27 02:23:55,305:INFO: test batch_id=140\n",
      "2021-05-27 02:23:55,308:INFO: test batch_id=141\n",
      "2021-05-27 02:23:55,311:INFO: test batch_id=142\n",
      "2021-05-27 02:23:55,315:INFO: test batch_id=143\n",
      "2021-05-27 02:23:55,317:INFO: test batch_id=144\n",
      "2021-05-27 02:23:55,321:INFO: test batch_id=145\n",
      "2021-05-27 02:23:55,324:INFO: test batch_id=146\n",
      "2021-05-27 02:23:55,327:INFO: test batch_id=147\n",
      "2021-05-27 02:23:55,330:INFO: test batch_id=148\n",
      "2021-05-27 02:23:55,332:INFO: test batch_id=149\n",
      "2021-05-27 02:23:55,335:INFO: test batch_id=150\n",
      "2021-05-27 02:23:55,338:INFO: test batch_id=151\n",
      "2021-05-27 02:23:55,341:INFO: test batch_id=152\n",
      "2021-05-27 02:23:55,343:INFO: test batch_id=153\n",
      "2021-05-27 02:23:55,346:INFO: test batch_id=154\n",
      "2021-05-27 02:23:55,349:INFO: test batch_id=155\n",
      "2021-05-27 02:23:55,351:INFO: test batch_id=156\n",
      "2021-05-27 02:23:55,354:INFO: test batch_id=157\n",
      "2021-05-27 02:23:55,357:INFO: test batch_id=158\n",
      "2021-05-27 02:23:55,360:INFO: test batch_id=159\n",
      "2021-05-27 02:23:55,362:INFO: test batch_id=160\n",
      "2021-05-27 02:23:55,365:INFO: test batch_id=161\n",
      "2021-05-27 02:23:55,367:INFO: test batch_id=162\n",
      "2021-05-27 02:23:55,370:INFO: test batch_id=163\n",
      "2021-05-27 02:23:55,373:INFO: test batch_id=164\n",
      "2021-05-27 02:23:55,377:INFO: test batch_id=165\n",
      "2021-05-27 02:23:55,380:INFO: test batch_id=166\n",
      "2021-05-27 02:23:55,382:INFO: test batch_id=167\n",
      "2021-05-27 02:23:55,385:INFO: test batch_id=168\n",
      "2021-05-27 02:23:55,388:INFO: test batch_id=169\n",
      "2021-05-27 02:23:55,390:INFO: test batch_id=170\n",
      "2021-05-27 02:23:55,394:INFO: test batch_id=171\n",
      "2021-05-27 02:23:55,398:INFO: test batch_id=172\n",
      "2021-05-27 02:23:55,400:INFO: test batch_id=173\n",
      "2021-05-27 02:23:55,403:INFO: test batch_id=174\n",
      "2021-05-27 02:23:55,406:INFO: test batch_id=175\n",
      "2021-05-27 02:23:55,409:INFO: test batch_id=176\n",
      "2021-05-27 02:23:55,413:INFO: test batch_id=177\n",
      "2021-05-27 02:23:55,416:INFO: test batch_id=178\n",
      "2021-05-27 02:23:55,419:INFO: test batch_id=179\n",
      "2021-05-27 02:23:55,422:INFO: test batch_id=180\n",
      "2021-05-27 02:23:55,426:INFO: test batch_id=181\n",
      "2021-05-27 02:23:55,430:INFO: test batch_id=182\n",
      "2021-05-27 02:23:55,432:INFO: test batch_id=183\n",
      "2021-05-27 02:23:55,435:INFO: test batch_id=184\n",
      "2021-05-27 02:23:55,438:INFO: test batch_id=185\n",
      "2021-05-27 02:23:55,442:INFO: test batch_id=186\n",
      "2021-05-27 02:23:55,446:INFO: test batch_id=187\n",
      "2021-05-27 02:23:55,448:INFO: test batch_id=188\n",
      "2021-05-27 02:23:55,452:INFO: test batch_id=189\n",
      "2021-05-27 02:23:55,456:INFO: test batch_id=190\n",
      "2021-05-27 02:23:55,458:INFO: test batch_id=191\n",
      "2021-05-27 02:23:55,462:INFO: test batch_id=192\n",
      "2021-05-27 02:23:55,465:INFO: test batch_id=193\n",
      "2021-05-27 02:23:55,469:INFO: test batch_id=194\n",
      "2021-05-27 02:23:55,471:INFO: test batch_id=195\n",
      "2021-05-27 02:23:55,475:INFO: test batch_id=196\n",
      "2021-05-27 02:23:55,479:INFO: test batch_id=197\n",
      "2021-05-27 02:23:55,482:INFO: test batch_id=198\n",
      "2021-05-27 02:23:55,485:INFO: test batch_id=199\n",
      "2021-05-27 02:23:55,489:INFO: test batch_id=200\n",
      "2021-05-27 02:23:55,493:INFO: test batch_id=201\n",
      "2021-05-27 02:23:55,496:INFO: test batch_id=202\n",
      "2021-05-27 02:23:55,499:INFO: test batch_id=203\n",
      "2021-05-27 02:23:55,502:INFO: test batch_id=204\n",
      "2021-05-27 02:23:55,505:INFO: test batch_id=205\n",
      "2021-05-27 02:23:55,508:INFO: test batch_id=206\n",
      "2021-05-27 02:23:55,511:INFO: test batch_id=207\n",
      "2021-05-27 02:23:55,514:INFO: test batch_id=208\n",
      "2021-05-27 02:23:55,517:INFO: test batch_id=209\n",
      "2021-05-27 02:23:55,520:INFO: test batch_id=210\n",
      "2021-05-27 02:23:55,523:INFO: test batch_id=211\n",
      "2021-05-27 02:23:55,526:INFO: test batch_id=212\n",
      "2021-05-27 02:23:55,529:INFO: test batch_id=213\n",
      "2021-05-27 02:23:55,532:INFO: test batch_id=214\n",
      "2021-05-27 02:23:55,535:INFO: test batch_id=215\n",
      "2021-05-27 02:23:55,538:INFO: test batch_id=216\n",
      "2021-05-27 02:23:55,541:INFO: test batch_id=217\n",
      "2021-05-27 02:23:55,545:INFO: test batch_id=218\n",
      "2021-05-27 02:23:55,549:INFO: test batch_id=219\n",
      "2021-05-27 02:23:55,551:INFO: test batch_id=220\n",
      "2021-05-27 02:23:55,554:INFO: test batch_id=221\n",
      "2021-05-27 02:23:55,557:INFO: test batch_id=222\n",
      "2021-05-27 02:23:55,560:INFO: test batch_id=223\n",
      "2021-05-27 02:23:55,562:INFO: test batch_id=224\n",
      "2021-05-27 02:23:55,565:INFO: test batch_id=225\n",
      "2021-05-27 02:23:55,570:INFO: test batch_id=226\n",
      "2021-05-27 02:23:55,572:INFO: test batch_id=227\n",
      "2021-05-27 02:23:55,575:INFO: test batch_id=228\n",
      "2021-05-27 02:23:55,580:INFO: test batch_id=229\n",
      "2021-05-27 02:23:55,583:INFO: test batch_id=230\n",
      "2021-05-27 02:23:55,587:INFO: test batch_id=231\n",
      "2021-05-27 02:23:55,590:INFO: test batch_id=232\n",
      "2021-05-27 02:23:55,595:INFO: test batch_id=233\n",
      "2021-05-27 02:23:55,599:INFO: test batch_id=234\n",
      "2021-05-27 02:23:55,601:INFO: test batch_id=235\n",
      "2021-05-27 02:23:55,606:INFO: test batch_id=236\n",
      "2021-05-27 02:23:55,609:INFO: test batch_id=237\n",
      "Accuracy of the network on test set: 90 %\n"
     ]
    }
   ],
   "source": [
    "model_test(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用模型预测\n",
    "import torch\n",
    "#在入模型\n",
    "emb_dim = 300\n",
    "hidden_size = 200\n",
    "label_size = 4\n",
    "\n",
    "model = torch.load(\"ag_fasttext_model.pkl\")\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#赋予标签\n",
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "#要预测的句子\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text = tokenizer(text)\n",
    "    text = torch.tensor([vocab[t] for t in text[:128]])\n",
    "    outputs = model(text)\n",
    "    predicted = torch.max(outputs.data, 1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x128 and 300x200)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-4de097d0d99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_text_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-cb7c3c096396>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-004082d42190>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x128 and 300x200)"
     ]
    }
   ],
   "source": [
    "predict(ex_text_str)"
   ]
  }
 ]
}