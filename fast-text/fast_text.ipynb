{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0729c69a4684e8a65c2caa3ee004518027c93c29c3ae5e222a8933f5bf005cb71",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../dataset/ag_news/train.csv', index_col=None)\n",
    "df_test = pd.read_csv('../dataset/ag_news/test.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Class Index  ...                                        Description\n",
       "0            3  ...  Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1            3  ...  Reuters - Private investment firm Carlyle Grou...\n",
       "2            3  ...  Reuters - Soaring crude prices plus worries\\ab...\n",
       "3            3  ...  Reuters - Authorities have halted oil export\\f...\n",
       "4            3  ...  AFP - Tearaway world oil prices, toppling reco...\n",
       "\n",
       "[5 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class Index</th>\n      <th>Title</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>Reuters - Private investment firm Carlyle Grou...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>Reuters - Authorities have halted oil export\\f...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "## Data Preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from torchtext.data import Iterator, BucketIterator, TabularDataset\n",
    "from torchtext import data\n",
    "from torchtext.vocab import Vectors, GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据并构建数据迭代器\n",
    "def get_data_iter(train_csv, test_csv, fix_length):\n",
    "\n",
    "    #定义text的对象，定长，小写，tokenizer\n",
    "    TEXT = data.Field(sequential=True, lower=True, tokenize=tokenizer, fix_length=fix_length, batch_first=True)\n",
    "    #定义LABEL对象\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "    train_fields = [(\"label\", LABEL), (\"title\", None), (\"text\", TEXT)]\n",
    "    train = TabularDataset(path=train_csv, format=\"csv\", fields=train_fields, skip_header=True)\n",
    "    train_iter = BucketIterator(train, batch_size=32, device=-1, sort_key=lambda x: len(x.text),\n",
    "                                sort_within_batch=False, repeat=False)\n",
    "\n",
    "    test_fields = [(\"label\", LABEL), (\"title\", None), (\"text\", TEXT)]\n",
    "    test = TabularDataset(path=test_csv, format=\"csv\", fields=test_fields, skip_header=True)\n",
    "    test_iter = Iterator(test, batch_size=32, device=-1, sort=False, sort_within_batch=False, repeat=False)\n",
    "\n",
    "    # vectors = Vectors(name=word2vec_dir)\n",
    "    #构建词表\n",
    "    TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=300))\n",
    "\n",
    "    vocab = TEXT.vocab\n",
    "\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter, vocab = get_data_iter('../dataset/ag_news/train.csv', '../dataset/ag_news/test.csv', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ")\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n",
      "torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "# for batch in train_iter:\n",
    "    # print(batch.text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext 模型\n",
    "class FastText(nn.Module):\n",
    "    def __init__(self, vocab, vec_dim, label_size, hidden_size):\n",
    "        super(FastText, self).__init__()\n",
    "        #创建embedding\n",
    "        self.embed = nn.Embedding(len(vocab), vec_dim)\n",
    "        # 若使用预训练的词向量，需在此处指定预训练的权重\n",
    "        self.embed.weight.data.copy_(vocab.vectors)\n",
    "        self.embed.weight.requires_grad = True\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(vec_dim, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_size, label_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('1', x.shape)\n",
    "        x = self.embed(x)\n",
    "        # print('2', x.shape)\n",
    "        # print(x.shape)\n",
    "        # print('3', torch.mean(x, dim=1).shape)\n",
    "        out = self.fc(torch.mean(x, dim=1))\n",
    "        # x = torch.flatten(x, start_dim=1)\n",
    "        # out = self.fc(x)\n",
    "        # print('4', out.shape)\n",
    "        # print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FastText(\n  (embed): Embedding(81641, 300)\n  (fc): Sequential(\n    (0): Linear(in_features=300, out_features=200, bias=True)\n    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Linear(in_features=200, out_features=4, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 300\n",
    "hidden_size = 200\n",
    "label_size = 4\n",
    "\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "#batchsize=32\n",
    "\n",
    "net = FastText(vocab=vocab, vec_dim=emb_dim, label_size=label_size, hidden_size=hidden_size)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_iter, epoch, lr):\n",
    "    print(\"begin training\")\n",
    "    net.train()  # 必备，将模型设置为训练模式\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for i in range(epoch):  # 多批次循环\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            # 注意target=batch.label - 1，因为数据集中的label是1，2，3，4，但是pytorch的label默认是从0开始，所以这里需要减1\n",
    "            data, target = batch.text, batch.label - 1\n",
    "            # print('*',data.shape)\n",
    "\n",
    "            optimizer.zero_grad()  # 清除所有优化的梯度\n",
    "            \n",
    "            output = net(data)  # 传入数据并前向传播获取输出\n",
    "            # print('**', output.shape)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_size = 32\n",
    "            # 打印状态信息\n",
    "            logging.info(\n",
    "                \"train epoch=\" + str(i) + \",batch_id=\" + str(batch_idx) + \",loss=\" + str(loss.item() / batch_size))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(net, test_iter):\n",
    "    net.eval()  # 必备，将模型设置为训练模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(test_iter):\n",
    "            # 注意target=batch.label - 1，因为数据集中的label是1，2，3，4，但是pytorch的label默认是从0开始，所以这里需要减1\n",
    "            data, label = batch.text, batch.label - 1\n",
    "            logging.info(\"test batch_id=\" + str(i))\n",
    "            outputs = net(data)\n",
    "            # torch.max()[0]表示最大值的值，troch.max()[1]表示回最大值的每个索引\n",
    "            # print(outputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 每个output是一行n列的数据，取一行中最大的值\n",
    "            # print(predicted)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "    print('Accuracy of the network on test set: %d %%' % (100 * correct / total))\n",
    "            # test_acc += accuracy_score(torch.argmax(outputs.data, dim=1), label)\n",
    "            # logging.info(\"test_acc=\" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-06-06 00:29:43,544:INFO: 开始训练模型\n",
      "begin training\n",
      "2021-06-06 00:29:43,807:INFO: train epoch=0,batch_id=0,loss=0.045218661427497864\n",
      "2021-06-06 00:29:43,880:INFO: train epoch=0,batch_id=1,loss=0.04231252148747444\n",
      "2021-06-06 00:29:43,952:INFO: train epoch=0,batch_id=2,loss=0.03718787804245949\n",
      "2021-06-06 00:29:44,027:INFO: train epoch=0,batch_id=3,loss=0.03754382207989693\n",
      "2021-06-06 00:29:44,103:INFO: train epoch=0,batch_id=4,loss=0.02481074631214142\n",
      "2021-06-06 00:29:44,179:INFO: train epoch=0,batch_id=5,loss=0.02969186194241047\n",
      "2021-06-06 00:29:44,252:INFO: train epoch=0,batch_id=6,loss=0.023758629336953163\n",
      "2021-06-06 00:29:44,328:INFO: train epoch=0,batch_id=7,loss=0.026689499616622925\n",
      "2021-06-06 00:29:44,405:INFO: train epoch=0,batch_id=8,loss=0.022018836811184883\n",
      "2021-06-06 00:29:44,479:INFO: train epoch=0,batch_id=9,loss=0.01987730897963047\n",
      "2021-06-06 00:29:44,562:INFO: train epoch=0,batch_id=10,loss=0.02105369046330452\n",
      "2021-06-06 00:29:44,642:INFO: train epoch=0,batch_id=11,loss=0.022477470338344574\n",
      "2021-06-06 00:29:44,719:INFO: train epoch=0,batch_id=12,loss=0.015048917382955551\n",
      "2021-06-06 00:29:44,792:INFO: train epoch=0,batch_id=13,loss=0.0188590157777071\n",
      "2021-06-06 00:29:44,865:INFO: train epoch=0,batch_id=14,loss=0.014733548276126385\n",
      "2021-06-06 00:29:44,940:INFO: train epoch=0,batch_id=15,loss=0.016902979463338852\n",
      "2021-06-06 00:29:45,020:INFO: train epoch=0,batch_id=16,loss=0.017903916537761688\n",
      "2021-06-06 00:29:45,094:INFO: train epoch=0,batch_id=17,loss=0.0219755657017231\n",
      "2021-06-06 00:29:45,165:INFO: train epoch=0,batch_id=18,loss=0.017047826200723648\n",
      "2021-06-06 00:29:45,238:INFO: train epoch=0,batch_id=19,loss=0.024915440008044243\n",
      "2021-06-06 00:29:45,315:INFO: train epoch=0,batch_id=20,loss=0.01728198677301407\n",
      "2021-06-06 00:29:45,393:INFO: train epoch=0,batch_id=21,loss=0.011531693860888481\n",
      "2021-06-06 00:29:45,470:INFO: train epoch=0,batch_id=22,loss=0.019063198938965797\n",
      "2021-06-06 00:29:45,550:INFO: train epoch=0,batch_id=23,loss=0.009642861783504486\n",
      "2021-06-06 00:29:45,628:INFO: train epoch=0,batch_id=24,loss=0.009916351176798344\n",
      "2021-06-06 00:29:45,706:INFO: train epoch=0,batch_id=25,loss=0.01621900126338005\n",
      "2021-06-06 00:29:45,782:INFO: train epoch=0,batch_id=26,loss=0.01110466755926609\n",
      "2021-06-06 00:29:45,859:INFO: train epoch=0,batch_id=27,loss=0.011825082823634148\n",
      "2021-06-06 00:29:45,933:INFO: train epoch=0,batch_id=28,loss=0.014532918110489845\n",
      "2021-06-06 00:29:46,009:INFO: train epoch=0,batch_id=29,loss=0.019054414704442024\n",
      "2021-06-06 00:29:46,082:INFO: train epoch=0,batch_id=30,loss=0.010508516803383827\n",
      "2021-06-06 00:29:46,163:INFO: train epoch=0,batch_id=31,loss=0.015651073306798935\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-49a4fa03432c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"开始训练模型\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# torch.save(net, net_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a93d1fae87f9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, train_iter, epoch, lr)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# print('*',data.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 清除所有优化的梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 传入数据并前向传播获取输出\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s: %(message)s', level=logging.INFO)\n",
    "\n",
    "#save model\n",
    "# net_dir = \"ag_fasttext_model.pkl\"\n",
    "emb_dim = 300\n",
    "hidden_size = 200\n",
    "label_size = 4\n",
    "\n",
    "epoch = 10\n",
    "lr = 0.001\n",
    "#batchsize=32\n",
    "\n",
    "net = FastText(vocab=vocab, vec_dim=emb_dim, label_size=label_size, hidden_size=hidden_size)\n",
    "\n",
    "logging.info(\"开始训练模型\")\n",
    "train_model(net, train_iter, epoch, lr)\n",
    "# torch.save(net, net_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dir = \"ag_fasttext_model.pkl\"\n",
    "torch.save(net, net_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-05-27 02:23:54,839:INFO: test batch_id=0\n",
      "2021-05-27 02:23:54,843:INFO: test batch_id=1\n",
      "2021-05-27 02:23:54,847:INFO: test batch_id=2\n",
      "2021-05-27 02:23:54,851:INFO: test batch_id=3\n",
      "2021-05-27 02:23:54,854:INFO: test batch_id=4\n",
      "2021-05-27 02:23:54,857:INFO: test batch_id=5\n",
      "2021-05-27 02:23:54,860:INFO: test batch_id=6\n",
      "2021-05-27 02:23:54,863:INFO: test batch_id=7\n",
      "2021-05-27 02:23:54,866:INFO: test batch_id=8\n",
      "2021-05-27 02:23:54,869:INFO: test batch_id=9\n",
      "2021-05-27 02:23:54,871:INFO: test batch_id=10\n",
      "2021-05-27 02:23:54,874:INFO: test batch_id=11\n",
      "2021-05-27 02:23:54,878:INFO: test batch_id=12\n",
      "2021-05-27 02:23:54,881:INFO: test batch_id=13\n",
      "2021-05-27 02:23:54,884:INFO: test batch_id=14\n",
      "2021-05-27 02:23:54,887:INFO: test batch_id=15\n",
      "2021-05-27 02:23:54,889:INFO: test batch_id=16\n",
      "2021-05-27 02:23:54,892:INFO: test batch_id=17\n",
      "2021-05-27 02:23:54,895:INFO: test batch_id=18\n",
      "2021-05-27 02:23:54,899:INFO: test batch_id=19\n",
      "2021-05-27 02:23:54,902:INFO: test batch_id=20\n",
      "2021-05-27 02:23:54,905:INFO: test batch_id=21\n",
      "2021-05-27 02:23:54,908:INFO: test batch_id=22\n",
      "2021-05-27 02:23:54,911:INFO: test batch_id=23\n",
      "2021-05-27 02:23:54,915:INFO: test batch_id=24\n",
      "2021-05-27 02:23:54,918:INFO: test batch_id=25\n",
      "2021-05-27 02:23:54,920:INFO: test batch_id=26\n",
      "2021-05-27 02:23:54,923:INFO: test batch_id=27\n",
      "2021-05-27 02:23:54,927:INFO: test batch_id=28\n",
      "2021-05-27 02:23:54,929:INFO: test batch_id=29\n",
      "2021-05-27 02:23:54,932:INFO: test batch_id=30\n",
      "2021-05-27 02:23:54,936:INFO: test batch_id=31\n",
      "2021-05-27 02:23:54,940:INFO: test batch_id=32\n",
      "2021-05-27 02:23:54,943:INFO: test batch_id=33\n",
      "2021-05-27 02:23:54,946:INFO: test batch_id=34\n",
      "2021-05-27 02:23:54,951:INFO: test batch_id=35\n",
      "2021-05-27 02:23:54,954:INFO: test batch_id=36\n",
      "2021-05-27 02:23:54,957:INFO: test batch_id=37\n",
      "2021-05-27 02:23:54,960:INFO: test batch_id=38\n",
      "2021-05-27 02:23:54,963:INFO: test batch_id=39\n",
      "2021-05-27 02:23:54,966:INFO: test batch_id=40\n",
      "2021-05-27 02:23:54,969:INFO: test batch_id=41\n",
      "2021-05-27 02:23:54,973:INFO: test batch_id=42\n",
      "2021-05-27 02:23:54,977:INFO: test batch_id=43\n",
      "2021-05-27 02:23:54,980:INFO: test batch_id=44\n",
      "2021-05-27 02:23:54,983:INFO: test batch_id=45\n",
      "2021-05-27 02:23:54,987:INFO: test batch_id=46\n",
      "2021-05-27 02:23:54,990:INFO: test batch_id=47\n",
      "2021-05-27 02:23:54,993:INFO: test batch_id=48\n",
      "2021-05-27 02:23:54,997:INFO: test batch_id=49\n",
      "2021-05-27 02:23:55,000:INFO: test batch_id=50\n",
      "2021-05-27 02:23:55,003:INFO: test batch_id=51\n",
      "2021-05-27 02:23:55,006:INFO: test batch_id=52\n",
      "2021-05-27 02:23:55,009:INFO: test batch_id=53\n",
      "2021-05-27 02:23:55,013:INFO: test batch_id=54\n",
      "2021-05-27 02:23:55,016:INFO: test batch_id=55\n",
      "2021-05-27 02:23:55,019:INFO: test batch_id=56\n",
      "2021-05-27 02:23:55,022:INFO: test batch_id=57\n",
      "2021-05-27 02:23:55,026:INFO: test batch_id=58\n",
      "2021-05-27 02:23:55,030:INFO: test batch_id=59\n",
      "2021-05-27 02:23:55,033:INFO: test batch_id=60\n",
      "2021-05-27 02:23:55,035:INFO: test batch_id=61\n",
      "2021-05-27 02:23:55,039:INFO: test batch_id=62\n",
      "2021-05-27 02:23:55,041:INFO: test batch_id=63\n",
      "2021-05-27 02:23:55,045:INFO: test batch_id=64\n",
      "2021-05-27 02:23:55,048:INFO: test batch_id=65\n",
      "2021-05-27 02:23:55,051:INFO: test batch_id=66\n",
      "2021-05-27 02:23:55,054:INFO: test batch_id=67\n",
      "2021-05-27 02:23:55,057:INFO: test batch_id=68\n",
      "2021-05-27 02:23:55,060:INFO: test batch_id=69\n",
      "2021-05-27 02:23:55,063:INFO: test batch_id=70\n",
      "2021-05-27 02:23:55,066:INFO: test batch_id=71\n",
      "2021-05-27 02:23:55,069:INFO: test batch_id=72\n",
      "2021-05-27 02:23:55,072:INFO: test batch_id=73\n",
      "2021-05-27 02:23:55,075:INFO: test batch_id=74\n",
      "2021-05-27 02:23:55,079:INFO: test batch_id=75\n",
      "2021-05-27 02:23:55,082:INFO: test batch_id=76\n",
      "2021-05-27 02:23:55,085:INFO: test batch_id=77\n",
      "2021-05-27 02:23:55,088:INFO: test batch_id=78\n",
      "2021-05-27 02:23:55,091:INFO: test batch_id=79\n",
      "2021-05-27 02:23:55,094:INFO: test batch_id=80\n",
      "2021-05-27 02:23:55,097:INFO: test batch_id=81\n",
      "2021-05-27 02:23:55,100:INFO: test batch_id=82\n",
      "2021-05-27 02:23:55,103:INFO: test batch_id=83\n",
      "2021-05-27 02:23:55,106:INFO: test batch_id=84\n",
      "2021-05-27 02:23:55,110:INFO: test batch_id=85\n",
      "2021-05-27 02:23:55,113:INFO: test batch_id=86\n",
      "2021-05-27 02:23:55,116:INFO: test batch_id=87\n",
      "2021-05-27 02:23:55,119:INFO: test batch_id=88\n",
      "2021-05-27 02:23:55,122:INFO: test batch_id=89\n",
      "2021-05-27 02:23:55,125:INFO: test batch_id=90\n",
      "2021-05-27 02:23:55,129:INFO: test batch_id=91\n",
      "2021-05-27 02:23:55,134:INFO: test batch_id=92\n",
      "2021-05-27 02:23:55,138:INFO: test batch_id=93\n",
      "2021-05-27 02:23:55,143:INFO: test batch_id=94\n",
      "2021-05-27 02:23:55,147:INFO: test batch_id=95\n",
      "2021-05-27 02:23:55,150:INFO: test batch_id=96\n",
      "2021-05-27 02:23:55,154:INFO: test batch_id=97\n",
      "2021-05-27 02:23:55,158:INFO: test batch_id=98\n",
      "2021-05-27 02:23:55,161:INFO: test batch_id=99\n",
      "2021-05-27 02:23:55,170:INFO: test batch_id=100\n",
      "2021-05-27 02:23:55,183:INFO: test batch_id=101\n",
      "2021-05-27 02:23:55,185:INFO: test batch_id=102\n",
      "2021-05-27 02:23:55,189:INFO: test batch_id=103\n",
      "2021-05-27 02:23:55,193:INFO: test batch_id=104\n",
      "2021-05-27 02:23:55,196:INFO: test batch_id=105\n",
      "2021-05-27 02:23:55,199:INFO: test batch_id=106\n",
      "2021-05-27 02:23:55,206:INFO: test batch_id=107\n",
      "2021-05-27 02:23:55,209:INFO: test batch_id=108\n",
      "2021-05-27 02:23:55,212:INFO: test batch_id=109\n",
      "2021-05-27 02:23:55,215:INFO: test batch_id=110\n",
      "2021-05-27 02:23:55,218:INFO: test batch_id=111\n",
      "2021-05-27 02:23:55,221:INFO: test batch_id=112\n",
      "2021-05-27 02:23:55,224:INFO: test batch_id=113\n",
      "2021-05-27 02:23:55,227:INFO: test batch_id=114\n",
      "2021-05-27 02:23:55,229:INFO: test batch_id=115\n",
      "2021-05-27 02:23:55,232:INFO: test batch_id=116\n",
      "2021-05-27 02:23:55,235:INFO: test batch_id=117\n",
      "2021-05-27 02:23:55,237:INFO: test batch_id=118\n",
      "2021-05-27 02:23:55,240:INFO: test batch_id=119\n",
      "2021-05-27 02:23:55,243:INFO: test batch_id=120\n",
      "2021-05-27 02:23:55,246:INFO: test batch_id=121\n",
      "2021-05-27 02:23:55,249:INFO: test batch_id=122\n",
      "2021-05-27 02:23:55,252:INFO: test batch_id=123\n",
      "2021-05-27 02:23:55,254:INFO: test batch_id=124\n",
      "2021-05-27 02:23:55,257:INFO: test batch_id=125\n",
      "2021-05-27 02:23:55,260:INFO: test batch_id=126\n",
      "2021-05-27 02:23:55,263:INFO: test batch_id=127\n",
      "2021-05-27 02:23:55,268:INFO: test batch_id=128\n",
      "2021-05-27 02:23:55,271:INFO: test batch_id=129\n",
      "2021-05-27 02:23:55,274:INFO: test batch_id=130\n",
      "2021-05-27 02:23:55,277:INFO: test batch_id=131\n",
      "2021-05-27 02:23:55,280:INFO: test batch_id=132\n",
      "2021-05-27 02:23:55,284:INFO: test batch_id=133\n",
      "2021-05-27 02:23:55,287:INFO: test batch_id=134\n",
      "2021-05-27 02:23:55,290:INFO: test batch_id=135\n",
      "2021-05-27 02:23:55,293:INFO: test batch_id=136\n",
      "2021-05-27 02:23:55,296:INFO: test batch_id=137\n",
      "2021-05-27 02:23:55,299:INFO: test batch_id=138\n",
      "2021-05-27 02:23:55,302:INFO: test batch_id=139\n",
      "2021-05-27 02:23:55,305:INFO: test batch_id=140\n",
      "2021-05-27 02:23:55,308:INFO: test batch_id=141\n",
      "2021-05-27 02:23:55,311:INFO: test batch_id=142\n",
      "2021-05-27 02:23:55,315:INFO: test batch_id=143\n",
      "2021-05-27 02:23:55,317:INFO: test batch_id=144\n",
      "2021-05-27 02:23:55,321:INFO: test batch_id=145\n",
      "2021-05-27 02:23:55,324:INFO: test batch_id=146\n",
      "2021-05-27 02:23:55,327:INFO: test batch_id=147\n",
      "2021-05-27 02:23:55,330:INFO: test batch_id=148\n",
      "2021-05-27 02:23:55,332:INFO: test batch_id=149\n",
      "2021-05-27 02:23:55,335:INFO: test batch_id=150\n",
      "2021-05-27 02:23:55,338:INFO: test batch_id=151\n",
      "2021-05-27 02:23:55,341:INFO: test batch_id=152\n",
      "2021-05-27 02:23:55,343:INFO: test batch_id=153\n",
      "2021-05-27 02:23:55,346:INFO: test batch_id=154\n",
      "2021-05-27 02:23:55,349:INFO: test batch_id=155\n",
      "2021-05-27 02:23:55,351:INFO: test batch_id=156\n",
      "2021-05-27 02:23:55,354:INFO: test batch_id=157\n",
      "2021-05-27 02:23:55,357:INFO: test batch_id=158\n",
      "2021-05-27 02:23:55,360:INFO: test batch_id=159\n",
      "2021-05-27 02:23:55,362:INFO: test batch_id=160\n",
      "2021-05-27 02:23:55,365:INFO: test batch_id=161\n",
      "2021-05-27 02:23:55,367:INFO: test batch_id=162\n",
      "2021-05-27 02:23:55,370:INFO: test batch_id=163\n",
      "2021-05-27 02:23:55,373:INFO: test batch_id=164\n",
      "2021-05-27 02:23:55,377:INFO: test batch_id=165\n",
      "2021-05-27 02:23:55,380:INFO: test batch_id=166\n",
      "2021-05-27 02:23:55,382:INFO: test batch_id=167\n",
      "2021-05-27 02:23:55,385:INFO: test batch_id=168\n",
      "2021-05-27 02:23:55,388:INFO: test batch_id=169\n",
      "2021-05-27 02:23:55,390:INFO: test batch_id=170\n",
      "2021-05-27 02:23:55,394:INFO: test batch_id=171\n",
      "2021-05-27 02:23:55,398:INFO: test batch_id=172\n",
      "2021-05-27 02:23:55,400:INFO: test batch_id=173\n",
      "2021-05-27 02:23:55,403:INFO: test batch_id=174\n",
      "2021-05-27 02:23:55,406:INFO: test batch_id=175\n",
      "2021-05-27 02:23:55,409:INFO: test batch_id=176\n",
      "2021-05-27 02:23:55,413:INFO: test batch_id=177\n",
      "2021-05-27 02:23:55,416:INFO: test batch_id=178\n",
      "2021-05-27 02:23:55,419:INFO: test batch_id=179\n",
      "2021-05-27 02:23:55,422:INFO: test batch_id=180\n",
      "2021-05-27 02:23:55,426:INFO: test batch_id=181\n",
      "2021-05-27 02:23:55,430:INFO: test batch_id=182\n",
      "2021-05-27 02:23:55,432:INFO: test batch_id=183\n",
      "2021-05-27 02:23:55,435:INFO: test batch_id=184\n",
      "2021-05-27 02:23:55,438:INFO: test batch_id=185\n",
      "2021-05-27 02:23:55,442:INFO: test batch_id=186\n",
      "2021-05-27 02:23:55,446:INFO: test batch_id=187\n",
      "2021-05-27 02:23:55,448:INFO: test batch_id=188\n",
      "2021-05-27 02:23:55,452:INFO: test batch_id=189\n",
      "2021-05-27 02:23:55,456:INFO: test batch_id=190\n",
      "2021-05-27 02:23:55,458:INFO: test batch_id=191\n",
      "2021-05-27 02:23:55,462:INFO: test batch_id=192\n",
      "2021-05-27 02:23:55,465:INFO: test batch_id=193\n",
      "2021-05-27 02:23:55,469:INFO: test batch_id=194\n",
      "2021-05-27 02:23:55,471:INFO: test batch_id=195\n",
      "2021-05-27 02:23:55,475:INFO: test batch_id=196\n",
      "2021-05-27 02:23:55,479:INFO: test batch_id=197\n",
      "2021-05-27 02:23:55,482:INFO: test batch_id=198\n",
      "2021-05-27 02:23:55,485:INFO: test batch_id=199\n",
      "2021-05-27 02:23:55,489:INFO: test batch_id=200\n",
      "2021-05-27 02:23:55,493:INFO: test batch_id=201\n",
      "2021-05-27 02:23:55,496:INFO: test batch_id=202\n",
      "2021-05-27 02:23:55,499:INFO: test batch_id=203\n",
      "2021-05-27 02:23:55,502:INFO: test batch_id=204\n",
      "2021-05-27 02:23:55,505:INFO: test batch_id=205\n",
      "2021-05-27 02:23:55,508:INFO: test batch_id=206\n",
      "2021-05-27 02:23:55,511:INFO: test batch_id=207\n",
      "2021-05-27 02:23:55,514:INFO: test batch_id=208\n",
      "2021-05-27 02:23:55,517:INFO: test batch_id=209\n",
      "2021-05-27 02:23:55,520:INFO: test batch_id=210\n",
      "2021-05-27 02:23:55,523:INFO: test batch_id=211\n",
      "2021-05-27 02:23:55,526:INFO: test batch_id=212\n",
      "2021-05-27 02:23:55,529:INFO: test batch_id=213\n",
      "2021-05-27 02:23:55,532:INFO: test batch_id=214\n",
      "2021-05-27 02:23:55,535:INFO: test batch_id=215\n",
      "2021-05-27 02:23:55,538:INFO: test batch_id=216\n",
      "2021-05-27 02:23:55,541:INFO: test batch_id=217\n",
      "2021-05-27 02:23:55,545:INFO: test batch_id=218\n",
      "2021-05-27 02:23:55,549:INFO: test batch_id=219\n",
      "2021-05-27 02:23:55,551:INFO: test batch_id=220\n",
      "2021-05-27 02:23:55,554:INFO: test batch_id=221\n",
      "2021-05-27 02:23:55,557:INFO: test batch_id=222\n",
      "2021-05-27 02:23:55,560:INFO: test batch_id=223\n",
      "2021-05-27 02:23:55,562:INFO: test batch_id=224\n",
      "2021-05-27 02:23:55,565:INFO: test batch_id=225\n",
      "2021-05-27 02:23:55,570:INFO: test batch_id=226\n",
      "2021-05-27 02:23:55,572:INFO: test batch_id=227\n",
      "2021-05-27 02:23:55,575:INFO: test batch_id=228\n",
      "2021-05-27 02:23:55,580:INFO: test batch_id=229\n",
      "2021-05-27 02:23:55,583:INFO: test batch_id=230\n",
      "2021-05-27 02:23:55,587:INFO: test batch_id=231\n",
      "2021-05-27 02:23:55,590:INFO: test batch_id=232\n",
      "2021-05-27 02:23:55,595:INFO: test batch_id=233\n",
      "2021-05-27 02:23:55,599:INFO: test batch_id=234\n",
      "2021-05-27 02:23:55,601:INFO: test batch_id=235\n",
      "2021-05-27 02:23:55,606:INFO: test batch_id=236\n",
      "2021-05-27 02:23:55,609:INFO: test batch_id=237\n",
      "Accuracy of the network on test set: 90 %\n"
     ]
    }
   ],
   "source": [
    "model_test(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用模型预测\n",
    "import torch\n",
    "#在入模型\n",
    "emb_dim = 300\n",
    "hidden_size = 200\n",
    "label_size = 4\n",
    "\n",
    "# model = torch.load(\"ag_fasttext_model.pkl\")\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#赋予标签\n",
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "#要预测的句子\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    model = torch.load(\"ag_fasttext_model.pkl\")\n",
    "    model.eval()\n",
    "    text = tokenizer(text)\n",
    "    text = torch.tensor([vocab[t] for t in text[:128]])\n",
    "    text = torch.unsqueeze(text, 0)\n",
    "    # print(text.size())\n",
    "    with torch.no_grad():\n",
    "        outputs = model(text)\n",
    "        # print(outputs.shape)\n",
    "        print(outputs)\n",
    "        predicted = torch.max(outputs.data, 1)\n",
    "    return predicted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-70.8558,  -1.5746, -26.5518,  34.4366]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Sci/Tec'"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "s = predict(ex_text_str)\n",
    "ag_news_label[int(s)+1]"
   ]
  }
 ]
}